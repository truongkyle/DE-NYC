# ---------- S3A (MinIO) ----------
spark.hadoop.fs.s3a.impl                     org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.endpoint                 http://minio:9000
spark.hadoop.fs.s3a.path.style.access        true
spark.hadoop.fs.s3a.connection.ssl.enabled   false
spark.hadoop.fs.s3a.access.key               minio_access_key
spark.hadoop.fs.s3a.secret.key               minio_secret_key
spark.hadoop.fs.s3a.aws.credentials.provider org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.fast.upload              true

# ---------- Hive Metastore ----------
spark.sql.catalogImplementation              hive
hive.metastore.uris                          thrift://hive-metastore:9083
spark.sql.warehouse.dir                      s3a://datalake/warehouse/

# ---------- Delta Lake ----------
spark.sql.extensions                         io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog              org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.delta.logStore.class                   org.apache.spark.sql.delta.storage.S3SingleDriverLogStore

# ---------- Master/Driver networking ----------
spark.master                                 spark://spark-master:7077
spark.submit.deployMode                      client
spark.driver.host                            spark-master
spark.driver.bindAddress                     0.0.0.0

# ---------- Observability (tùy chọn) ----------
# spark.ui.prometheus.enabled                  true
# spark.eventLog.enabled                       true
# spark.eventLog.dir                           s3a://datalake/spark-events/

spark.eventLog.enabled                       false

# ---------- Resource & Streaming Control ----------
spark.executor.instances                    1
spark.executor.cores                        2
spark.cores.max                             2
# spark.executor.memory                       2g
spark.driver.memory                         2g
spark.deploy.defaultCores                   2
# spark.sql.shuffle.partitions                8
spark.streaming.backpressure.enabled        true
spark.streaming.stopGracefullyOnShutdown    true

spark.dynamicAllocation.enabled             false


# Chia tài nguyên công bằng cho nhiều job
spark.scheduler.mode                        FAIR
spark.scheduler.allocation.file             /opt/spark/conf/fairscheduler.xml

